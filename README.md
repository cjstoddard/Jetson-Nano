# Jetson-Nano
Various AI projects for my Jetson Nano

I was lent a Dell Pro Max DG10 development system awhile back. I had it for about a week and it was a facinating piece of equipment. Unfortunately I did have to give it back, but the experience of having a machine like that strictly to develope AI applications was kind of fun. Also unfortunately, those things cost $4,000 which is outside of my budget. Fortunately, NVIDIA makes or rather made, smaller more affordable systems that serve the same purpose. Of course the Jetson Thor's and such were also out of my price range, but the Jetson Orin Nano came in at $250, not bad all things considered. Sure its not as powerful and leaves a lot of things to be desired, but for a little hobbyist toy, it works just fine for me.

This little machine only has 8 GB of RAM in total, this RAM is shared by both the CPU and the GPU. Hyopthetically, you should be able to use a 6 or 7 billion parameter model, however, in reailty, the overhead of the host operating system means this is much less. I have found about the biggest you can go is 4 billion (4b). The LLM used in Simple-chat is a 4b model and it is almost too much. The RAG chatbot is much smaller, 1.5b in fact. It had to be smaller because the RAG web frontend is much more complex, it also uses a secondary model. Both of these, when up and running, consume about the same amount of RAM. Of Course you could never run them at the same time on the Nano.

My goal with each of these projects is for each of them to be self contained and easy to deploy and reproducible, hence the build shell scripts. Everything should be in its own container, so as not to mess with anything other models and especially the host system. Hypathetically you should be able to build these on any Linux machine with Docker installed and a GPU with 8GB od VRAM. I have not tested them on anything other than my Nano, so milage may vary.
