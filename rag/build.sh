#!/usr/bin/env bash
# Clean build for Jetson RAG - Flask + 1.5B model
# Optimized balance of memory and quality

set -euo pipefail

ROOT="${HOME}/rag"

echo "=========================================="
echo "Jetson RAG - Flask Edition"
echo "Clean Build from Scratch"
echo "=========================================="
echo ""
echo "Configuration:"
echo "  ‚Ä¢ Frontend: Flask (lightweight)"
echo "  ‚Ä¢ Model: qwen2.5:1.5b (1.5B params)"
echo "  ‚Ä¢ Context: 512 tokens"
echo "  ‚Ä¢ Memory: ~2.5GB GPU RAM"
echo "  ‚Ä¢ Quality: Much better than minimal!"
echo ""

read -p "Start completely fresh? This will DELETE all data (y/n) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
  echo "[*] Complete cleanup..."
  cd "${ROOT}" && docker compose down 2>/dev/null || true
  rm -rf "${ROOT}/ollama" "${ROOT}/storage" "${ROOT}/data"
  echo "    ‚úì Clean slate ready"
fi

echo ""
echo "[*] Creating directory structure..."
mkdir -p "${ROOT}/data" "${ROOT}/storage" "${ROOT}/ollama"

echo ""
echo "[*] Creating test document..."
cat > "${ROOT}/data/test.txt" << 'EOF'
The Jetson Orin Nano Developer Kit is an AI computer from NVIDIA designed for edge AI and robotics.

Key Specifications:
- Memory: 8GB unified RAM (shared between CPU and GPU)
- GPU: 1024-core NVIDIA Ampere architecture GPU
- CPU: 6-core Arm Cortex-A78AE v8.2 64-bit
- AI Performance: Up to 40 TOPS (INT8)
- Power: 7W to 15W configurable
- Connectivity: Gigabit Ethernet, WiFi, Bluetooth

This developer kit is ideal for:
- AI inference at the edge
- Robotics applications
- Computer vision projects
- Natural language processing
- Autonomous machines

The system runs Ubuntu 20.04 and supports popular AI frameworks including TensorFlow, PyTorch, and ONNX.
EOF
echo "    ‚úì Test document created"

echo ""
echo "[*] Building RAG application image..."
docker compose -f "${ROOT}/docker-compose.yaml" build rag

echo ""
echo "[*] Starting Ollama service..."
docker compose -f "${ROOT}/docker-compose.yaml" up -d ollama

echo ""
echo "[*] Waiting for Ollama to be ready..."
for i in {1..60}; do
  if docker compose -f "${ROOT}/docker-compose.yaml" exec -T ollama curl -sf http://127.0.0.1:11434/api/tags >/dev/null 2>&1; then
    echo "    ‚úì Ollama is ready!"
    break
  fi
  printf "."
  sleep 1
  if [ $i -eq 60 ]; then
    echo ""
    echo "ERROR: Ollama failed to start after 60 seconds"
    echo "Check: docker compose logs ollama"
    exit 1
  fi
done
echo ""

echo ""
echo "=========================================="
echo "Downloading Models"
echo "=========================================="
echo ""

echo "[*] Pulling qwen2.5:1.5b (~1GB, 2-5 minutes)..."
echo "    This model is 3x better than the minimal 0.5b"
docker compose -f "${ROOT}/docker-compose.yaml" exec -T ollama ollama pull qwen2.5:1.5b

echo ""
echo "[*] Pulling nomic-embed-text (~274MB, 1 minute)..."
docker compose -f "${ROOT}/docker-compose.yaml" exec -T ollama ollama pull nomic-embed-text

echo ""
echo "[*] Verifying models are installed..."
docker compose -f "${ROOT}/docker-compose.yaml" exec -T ollama ollama list

echo ""
echo "[*] Testing embedding model..."
EMBED_TEST=$(docker compose -f "${ROOT}/docker-compose.yaml" exec -T ollama curl -s http://127.0.0.1:11434/api/embeddings -d '{"model":"nomic-embed-text","prompt":"test"}' 2>/dev/null)
if echo "$EMBED_TEST" | grep -q "embedding"; then
  echo "    ‚úì Embeddings working!"
else
  echo "    ‚ö† Embedding test inconclusive (may still work)"
fi

echo ""
echo "[*] Testing LLM..."
LLM_TEST=$(docker compose -f "${ROOT}/docker-compose.yaml" exec -T ollama curl -s http://127.0.0.1:11434/api/generate -d '{"model":"qwen2.5:1.5b","prompt":"hi","stream":false}' 2>/dev/null)
if echo "$LLM_TEST" | grep -q "response"; then
  echo "    ‚úì LLM working!"
else
  echo "    ‚ö† LLM test inconclusive (may still work)"
fi

echo ""
echo "[*] Disk space used by models..."
du -sh "${ROOT}/ollama" 2>/dev/null || echo "    ~1.3GB"

echo ""
echo "[*] Starting Flask RAG application..."
docker compose -f "${ROOT}/docker-compose.yaml" up -d rag

echo ""
echo "[*] Waiting for Flask to initialize (15 seconds)..."
sleep 15

echo ""
if docker compose -f "${ROOT}/docker-compose.yaml" ps rag | grep -q "Up"; then
  echo "=========================================="
  echo "‚úÖ SUCCESS - Flask RAG is Running!"
  echo "=========================================="
  echo ""
  echo "üéâ Access your RAG system:"
  echo "   http://localhost:7860"
  echo "   http://$(hostname -I | awk '{print $1}'):7860"
  echo ""
  echo "üìä Configuration:"
  echo "   ‚Ä¢ Frontend:   Flask (lightweight, ~50MB)"
  echo "   ‚Ä¢ LLM:        qwen2.5:1.5b (1.5B params)"
  echo "   ‚Ä¢ Embeddings: nomic-embed-text"
  echo "   ‚Ä¢ Context:    512 tokens"
  echo "   ‚Ä¢ GPU RAM:    ~2.5GB"
  echo ""
  echo "‚ú® Features:"
  echo "   ‚úÖ Beautiful, responsive web UI"
  echo "   ‚úÖ Upload documents via browser"
  echo "   ‚úÖ Much better answers than minimal"
  echo "   ‚úÖ Works on desktop and mobile"
  echo ""
  echo "üöÄ Getting Started:"
  echo "   1. Open http://localhost:7860 in browser"
  echo "   2. Upload a document (txt, pdf, md)"
  echo "   3. Click 'Upload & Reindex'"
  echo "   4. Ask a question about the document"
  echo "   5. Get intelligent answers!"
  echo ""
  echo "üìù Commands:"
  echo "   ‚Ä¢ View logs:  docker compose logs -f rag"
  echo "   ‚Ä¢ Stop:       docker compose down"
  echo "   ‚Ä¢ Restart:    docker compose restart rag"
  echo "   ‚Ä¢ Status:     docker compose ps"
  echo ""
  echo "üí° Tips:"
  echo "   ‚Ä¢ Be specific in your questions"
  echo "   ‚Ä¢ Upload clear, well-formatted documents"
  echo "   ‚Ä¢ Model handles ~300-400 words of context"
  echo "   ‚Ä¢ Press Ctrl+Enter in question box to submit"
  echo ""
else
  echo "=========================================="
  echo "‚ö†Ô∏è Warning - Check Status"
  echo "=========================================="
  echo ""
  echo "Container may have issues. Check logs:"
  echo "  docker compose logs rag"
  echo ""
  echo "Common issues:"
  echo "  1. Out of memory ‚Üí Check: sudo jtop"
  echo "  2. Model not loaded ‚Üí Check: docker compose logs ollama"
  echo "  3. Port in use ‚Üí Check: netstat -tulpn | grep 7860"
  echo ""
  echo "To restart:"
  echo "  docker compose restart rag"
  echo ""
fi

echo ""
echo "=========================================="
echo "System Information"
echo "=========================================="
echo ""
echo "Data locations:"
echo "  ‚Ä¢ Documents:   ${ROOT}/data"
echo "  ‚Ä¢ Index:       ${ROOT}/storage"
echo "  ‚Ä¢ Models:      ${ROOT}/ollama (~1.3GB)"
echo ""
echo "Model comparison:"
echo "  ‚Ä¢ 0.5B (minimal): Basic answers, fast"
echo "  ‚Ä¢ 1.5B (current): Good comprehension ‚≠ê"
echo "  ‚Ä¢ 3B (if more RAM): Better reasoning"
echo ""
echo "Memory usage (approximate):"
echo "  ‚Ä¢ Ollama:      ~2.5GB"
echo "  ‚Ä¢ Flask RAG:   ~300MB"
echo "  ‚Ä¢ Total:       ~2.8GB"
echo "  ‚Ä¢ Available:   ~5GB (for other tasks)"
echo ""
