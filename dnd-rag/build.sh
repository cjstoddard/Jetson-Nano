#!/usr/bin/env bash
# Build script for AI RAG Agent
# Inspired by n8n RAG setup from Hackster.io

set -euo pipefail

echo "=========================================="
echo "AI RAG Agent - Build Script"
echo "=========================================="
echo ""
echo "Based on: hackster.io/shahizat/build-local-ai-rag-agent-with-n8n"
echo "Simplified with Flask web interface instead of Telegram/n8n"
echo ""

# Check required files
echo "[*] Checking required files..."
if [ ! -f "rag-agent.py" ]; then
    echo "ERROR: rag-agent.py not found"
    exit 1
fi

if [ ! -f "docker-compose.yaml" ]; then
    echo "ERROR: docker-compose.yaml not found"
    exit 1
fi

echo "    ‚úì All required files present"

# Clean start option
echo ""
read -p "Clean start? This will remove old data (y/n) " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "[*] Cleaning old data..."
    docker compose down -v 2>/dev/null || true
    rm -rf ollama qdrant_storage uploads
    echo "    ‚úì Clean slate ready"
fi

echo ""
echo "[*] Creating directories..."
mkdir -p ollama qdrant_storage uploads
echo "    ‚úì Directories created"

echo ""
echo "=========================================="
echo "Building Docker Containers"
echo "=========================================="
echo ""
echo "This will:"
echo "  ‚Ä¢ Start Ollama for LLM and embeddings"
echo "  ‚Ä¢ Start Qdrant vector database"
echo "  ‚Ä¢ Build Flask RAG agent"
echo ""
echo "Build takes ~5 minutes..."
echo ""

docker compose build

echo ""
echo "=========================================="
echo "Starting Services"
echo "=========================================="
echo ""

# Start Ollama first
echo "[*] Starting Ollama..."
docker compose up -d ollama

echo ""
echo "[*] Waiting for Ollama to be ready..."
for i in {1..60}; do
    if docker compose exec -T ollama curl -sf http://127.0.0.1:11434/api/tags >/dev/null 2>&1; then
        echo "    ‚úì Ollama is ready!"
        break
    fi
    printf "."
    sleep 1
    if [ $i -eq 60 ]; then
        echo ""
        echo "ERROR: Ollama failed to start"
        exit 1
    fi
done
echo ""

# Pull required models
echo "[*] Pulling AI models..."
echo "    This will take 5-15 minutes on first run"
echo ""

echo "    [1/2] Pulling LLM model (qwen2.5:3b)..."
docker compose exec -T ollama ollama pull qwen2.5:3b

echo ""
echo "    [2/2] Pulling embedding model (nomic-embed-text)..."
docker compose exec -T ollama ollama pull nomic-embed-text

echo ""
echo "    ‚úì All models ready"

# Start Qdrant and RAG agent
echo ""
echo "[*] Starting Qdrant and RAG agent..."
docker compose up -d

echo ""
echo "[*] Waiting for RAG agent (30 seconds)..."
sleep 30

echo ""
if docker compose ps rag-agent | grep -q "Up"; then
    echo "=========================================="
    echo "‚úÖ SUCCESS - RAG Agent Running!"
    echo "=========================================="
    echo ""
    echo "üåê Access your RAG agent:"
    echo "   http://localhost:8080"
    echo "   http://$(hostname -I | awk '{print $1}'):8080"
    echo ""
    echo "üìä Component Ports:"
    echo "   ‚Ä¢ RAG Agent:  7861"
    echo "   ‚Ä¢ Ollama:     11437"
    echo "   ‚Ä¢ Qdrant:     6333 (API), 6334 (gRPC)"
    echo ""
    echo "üéØ Features:"
    echo "   ‚úì Upload documents (TXT, PDF, HTML)"
    echo "   ‚úì Ingest from URLs"
    echo "   ‚úì Chat with your knowledge base"
    echo "   ‚úì Conversational memory"
    echo "   ‚úì Source attribution"
    echo ""
    echo "üí° How to use:"
    echo "   1. Upload documents or add URLs"
    echo "   2. Wait for processing"
    echo "   3. Ask questions about your documents"
    echo "   4. Get AI-powered answers with context!"
    echo ""
    echo "üìù Commands:"
    echo "   ‚Ä¢ View logs:     docker compose logs -f rag-agent"
    echo "   ‚Ä¢ View Ollama:   docker compose logs -f ollama"
    echo "   ‚Ä¢ View Qdrant:   docker compose logs -f qdrant"
    echo "   ‚Ä¢ Stop all:      docker compose down"
    echo "   ‚Ä¢ Restart:       docker compose restart"
    echo ""
    echo "üîß Configuration:"
    echo "   ‚Ä¢ LLM Model:    qwen2.5:3b"
    echo "   ‚Ä¢ Embeddings:   nomic-embed-text"
    echo "   ‚Ä¢ Vector DB:    Qdrant"
    echo "   ‚Ä¢ Chunk size:   1000 tokens"
    echo ""
    echo "‚ö†Ô∏è  Memory Usage:"
    echo "   ‚Ä¢ Expected: ~3-4GB GPU RAM"
    echo "   ‚Ä¢ Check: sudo jtop"
    echo ""
    echo "üìñ Based on:"
    echo "   hackster.io/shahizat/build-local-ai-rag-agent-with-n8n"
    echo ""
else
    echo "=========================================="
    echo "‚ö†Ô∏è RAG Agent Status Unknown"
    echo "=========================================="
    echo ""
    echo "Check logs: docker compose logs rag-agent"
fi

echo ""
echo "=========================================="
echo "System Information"
echo "=========================================="
echo ""
echo "Container status:"
docker compose ps
echo ""
echo "Ollama models:"
docker compose exec -T ollama ollama list
echo ""
echo "Storage:"
du -sh ollama/ qdrant_storage/ uploads/
echo ""
echo "=========================================="
echo "Build Complete! ü§ñ"
echo "=========================================="
